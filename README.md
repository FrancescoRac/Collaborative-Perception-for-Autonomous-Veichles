# Collaborative-Perception-for-Autonomous-Veichles

All the required data can be downloaded here: https://uncloud.univ-nantes.fr/index.php/s/oiMzTpqiBGniZng

- Unzip the folder;
- In the file lab1/utils, make sure the root_path param is set to the root of the scenario1 folder.

### Description

This lab focuses on the utilization of Intelligent Road-Side Unit (IRSU) data, particularly in the context of enhanced vehicle perception and environment mapping. Students will work with LiDAR data and learn how to effectively visualize and interpret this data for autonomous vehicle applications.

## Task 1

Show measurements made by the Intelligent Road-Side Unit (IRSU) positioned at the center of the intersection:
- 1 point clouds collected by a 32-channel LiDAR

![image](https://github.com/user-attachments/assets/804a283e-b1bf-42dc-85b5-a91975cbf6b0)


## Task 2 

Enhancing Vehicle Perception with IRSU Data: 
- Learn how IRSU data can enhance the vehicle's field of view and perception range.

![image](https://github.com/user-attachments/assets/83860989-010c-455c-a9e7-b772f00d50fb)


## Task 3

Building an occupancy grid:
- Construct a Bird's Eye View (BEV) occupancy grid of the environment.
- Understand the significance of occupancy grids in autonomous vehicle navigation.

![image](https://github.com/user-attachments/assets/ba7950c9-4892-4911-ba09-f2a8dd61c4a8)

![image](https://github.com/user-attachments/assets/c366a421-fde6-4340-8ee0-c2e876317539)


## Task 4 

Build an occupancy grid map for each actor.

![image](https://github.com/user-attachments/assets/8c4a989c-5d71-4511-a556-e4158b43b0ae)

![image](https://github.com/user-attachments/assets/cbec3861-96ce-4860-ab03-764565e4c152)

![image](https://github.com/user-attachments/assets/2071cc03-a565-47a4-9f11-dc8c4455a6c7)

![image](https://github.com/user-attachments/assets/38a8ee12-27d8-4a6b-93c3-0dc9e27cf207)






