{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'visualization.py')\n",
    "sys.path.insert(0, 'utils.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "# /!\\ Before running the lab make sure every additional libraries is installed \n",
    "\n",
    "# Import local libraries\n",
    "from visualization import *\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task n째1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise is about showing measurements made by the Intelligent Road-Side Unit (IRSU) positioned at the center of the intersection:\n",
    "- 1 point clouds collected by a 32-channel LiDAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions you need to modify are located in:\n",
    "-  box_to_corner -> visualization.py \n",
    "\n",
    "-  get_boxes_in_actor_frame -> utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 8)\n"
     ]
    }
   ],
   "source": [
    "n_frame = 0\n",
    "actor = 'ego_vehicle'\n",
    "\n",
    "irsu_points = get_point_cloud(n_frame, actor)\n",
    "irsu_boxes = get_boxes_in_actor_frame(n_frame, actor)\n",
    "print(irsu_boxes.shape)\n",
    "box_colors = CLASS_COLORS[irsu_boxes[:, -1].astype(np.int32)]\n",
    "\n",
    "\n",
    "show_objects(irsu_points[:,:3], irsu_boxes[:,:7], box_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task n째2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise demonstrates how the field of view and perception range of a vehicle can be enhanced by receiving data from other vehicles and the IRSU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions you need to modify are:\n",
    "-  box_to_corner (already done in task 1) -> visualization.py\n",
    "-  get_available_point_clouds, get_available_boxes_in_ego_frame, get_boxes_in_actor_frame(already done in task 1) -> utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frame = 0\n",
    "actors = [\"ego_vehicle\" ,\"other_vehicle\",   \"ego_vehicle_behind\",\"other_vehicle_behind\" ,\"infrastructure\",]#\n",
    "\n",
    "merged_points = get_available_point_clouds(n_frame, actors)\n",
    "irsu_boxes = get_available_boxes_in_ego_frame(n_frame, actors)\n",
    "box_colors = CLASS_COLORS[irsu_boxes[:, -1].astype(np.int32)]\n",
    "\n",
    "show_objects(merged_points, irsu_boxes[:,:7], box_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task n째3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a BEV occupancy grid of the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A main challenge in perception on point clouds is their unordered nature which hinders the application of the Convolution operation, thus preventing the use of many wonders in the world of image-based perception. An effective way to get around this challenge is to convert point clouds to BEV images. In other word, to look at a point cloud from the top-view which is what you are going to do in this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions you need to modify are :\n",
    "-  box_to_pixels, points_to_pixels-> visualization.py\n",
    "-  filter_points -> utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_frame = 0\n",
    "actors = [\"ego_vehicle\" ,\"other_vehicle\",   \"ego_vehicle_behind\",\"other_vehicle_behind\",\"infrastructure\",]\n",
    "merged_points = get_available_point_clouds(n_frame, actors)\n",
    "irsu_boxes = get_available_boxes_in_ego_frame(n_frame, actors)\n",
    "box_colors = CLASS_COLORS[irsu_boxes[:, -1].astype(np.int32)]\n",
    "\n",
    "# ------------------ Get Waypoints that belongs to the ground floor ------------------\n",
    "points_range = np.array([-50, -50, -25, 50, 50, 0.01])  # xmin, ymin, zmin, xmax, ymax, zmax (meters) around ego_vehicle\n",
    "\n",
    "filtered_points = filter_points(merged_points, points_range)\n",
    "show_objects(filtered_points, irsu_boxes[:,:7], box_colors)\n",
    "\n",
    "# ------------------  Build BEV image  ------------------  \n",
    "bev_resolution = 0.1 # meters / pixel\n",
    "bev_imsize = np.ceil((points_range[3: 5] - points_range[:2]) / bev_resolution).astype(int)  # (width, height)\n",
    "bev_occupancy = np.zeros((bev_imsize[1], bev_imsize[0]))\n",
    "\n",
    "# ------------------  Project bbox of actors on the image  ------------------  \n",
    "\n",
    "#box_mask = box_to_pixels(irsu_boxes[:,:7], bev_imsize, bev_resolution)\n",
    "#bev_occupancy[box_mask > 0] = 255\n",
    "\n",
    "for i in range(irsu_boxes.shape[0]):\n",
    "    box_mask = box_to_pixels(irsu_boxes[i:i+1, :7], bev_imsize, bev_resolution)\n",
    "    bev_occupancy[box_mask > 0] = 255\n",
    "\n",
    "# ------------------  Project navigable space on the image ------------------  \n",
    "navigable_space = points_to_pixels(filtered_points, bev_imsize, bev_resolution)\n",
    "\n",
    "for pixel in navigable_space:\n",
    "    bev_occupancy[round(pixel[1]), round(pixel[0])] = 150\n",
    "\n",
    "\n",
    "plt.imshow(bev_occupancy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task n째4: \n",
    "Segment points according to object's class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_object_class(irsu_boxes):\n",
    "    \n",
    "    car_obj = np.empty((0, 7))\n",
    "    truck_obj = np.empty((0, 7))\n",
    "    ped_obj = np.empty((0, 7))\n",
    "    moto_obj = np.empty((0, 7))\n",
    "\n",
    "    for i in (irsu_boxes):\n",
    "        class_label = i[-1]\n",
    "        if class_label == 0.0:\n",
    "            car_obj = np.vstack((car_obj, i[0:7]))\n",
    "        elif class_label == 1.0:\n",
    "            truck_obj = np.vstack((truck_obj, i[0:7]))\n",
    "        elif class_label == 2.0:\n",
    "            moto_obj= np.vstack((moto_obj, i[0:7]))\n",
    "        else:\n",
    "            ped_obj= np.vstack((ped_obj, i[0:7]))\n",
    "            \n",
    "            \n",
    "    return car_obj, truck_obj, moto_obj, ped_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each detection is attached with one class label, use it to filter out the detections of interest (e.g. vehicles, pedestrians, etc.)\n",
    "\n",
    "# Each detection is attached with one class label, use it to filter out the detections of interest (e.g. vehicles, pedestrians, etc.)\n",
    "\n",
    "n_frame = 0\n",
    "actors = [\"ego_vehicle\" ,\"other_vehicle\",   \"ego_vehicle_behind\",\"other_vehicle_behind\",\"infrastructure\",]\n",
    "merged_points = get_available_point_clouds(n_frame, actors)\n",
    "irsu_boxes = get_available_boxes_in_ego_frame(n_frame, actors)    \n",
    "\n",
    "car_obj, truck_obj, moto_obj, ped_obj = segment_object_class(irsu_boxes)\n",
    "\n",
    "# ------------------  Build BEV image  ------------------  \n",
    "bev_resolution = 0.1 # meters / pixel\n",
    "bev_imsize = np.ceil((points_range[3: 5] - points_range[:2]) / bev_resolution).astype(int)  # (width, height)\n",
    "\n",
    "bev_occupancy_car = np.zeros((bev_imsize[1], bev_imsize[0]))\n",
    "bev_occupancy_truck = np.zeros((bev_imsize[1], bev_imsize[0]))\n",
    "bev_occupancy_ped = np.zeros((bev_imsize[1], bev_imsize[0]))\n",
    "bev_occupancy_moto = np.zeros((bev_imsize[1], bev_imsize[0]))\n",
    "\n",
    "# ------------------  Project bbox of actors on the image  ------------------  \n",
    "\n",
    "for i in range(car_obj.shape[0]):\n",
    "    box_mask_car = box_to_pixels(car_obj[i:i+1, :7], bev_imsize, bev_resolution)\n",
    "    bev_occupancy_car[box_mask_car > 0] = 255\n",
    "    \n",
    "for i in range(truck_obj.shape[0]):\n",
    "    box_mask_truck = box_to_pixels(truck_obj[i:i+1, :7], bev_imsize, bev_resolution)\n",
    "    bev_occupancy_truck[box_mask_truck > 0] = 255\n",
    "    \n",
    "for i in range(ped_obj.shape[0]):\n",
    "    box_mask_ped = box_to_pixels(ped_obj[i:i+1, :7], bev_imsize, bev_resolution)\n",
    "    bev_occupancy_ped[box_mask_ped > 0] = 255\n",
    "    \n",
    "for i in range(moto_obj.shape[0]):\n",
    "    box_mask_moto = box_to_pixels(moto_obj[i:i+1, :7], bev_imsize, bev_resolution)\n",
    "    bev_occupancy_moto[box_mask_moto > 0] = 255\n",
    "\n",
    "# ------------------  Project navigable space on the image ------------------\n",
    "navigable_space = points_to_pixels(filtered_points, bev_imsize, bev_resolution) # Da controllare\n",
    "\n",
    "for pixel in navigable_space:\n",
    "    bev_occupancy_car[round(pixel[1]), round(pixel[0])] = 150\n",
    "    bev_occupancy_truck[round(pixel[1]), round(pixel[0])] = 150\n",
    "    bev_occupancy_ped[round(pixel[1]), round(pixel[0])] = 150\n",
    "    bev_occupancy_moto[round(pixel[1]), round(pixel[0])] = 150\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(bev_occupancy_car)\n",
    "plt.title(\"Car Occupancy\")\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(bev_occupancy_truck)\n",
    "plt.title(\"Truck Occupancy\")\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(bev_occupancy_ped)\n",
    "plt.title(\"Pedestrian Occupancy\")\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(bev_occupancy_moto)\n",
    "plt.title(\"Moto Occupancy\")\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
